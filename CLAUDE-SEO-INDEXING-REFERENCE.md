# üìù CLAUDE REFERENCE: WHPCodes SEO Indexing Status Changes

## üéØ Purpose
This file contains step-by-step instructions for changing indexing status of /whop/ URLs on WHPCodes. Read this file whenever the user wants to move pages between indexable, noindex, or gone status.

## üóÑÔ∏è Database Schema (Neon Database)
**Table**: `Whop`
**Key Columns**:
- `indexingStatus`: `'INDEX' | 'NOINDEX'` 
- `retirement`: `'NONE' | 'REDIRECT' | 'GONE'`
- `retired`: boolean (legacy, still used)

## üìã Complete Process for Status Changes

### 1. Database Changes (User Must Do This)
**Prompt user to run these SQL commands in Neon dashboard:**

```sql
-- To make a page INDEXABLE (appears in index-1.xml)
UPDATE "Whop" SET "indexingStatus" = 'INDEX', "retirement" = 'NONE' 
WHERE slug = 'target-slug-name';

-- To NOINDEX a page (keep live but not searchable, appears in noindex.xml)
UPDATE "Whop" SET "indexingStatus" = 'NOINDEX', "retirement" = 'NONE' 
WHERE slug = 'target-slug-name';

-- To mark as GONE (410 status, appears in gone.xml)
UPDATE "Whop" SET "retirement" = 'GONE' 
WHERE slug = 'target-slug-name';
```

### 2. Regenerate SEO Files (Claude Does This)
Run these commands in project directory:

```bash
# Build everything (recommended - runs prebuild scripts)
npm run build

# OR manually run individual scripts:
npx ts-node scripts/build-seo-indexes.ts  # Updates NOINDEX_PATHS/RETIRED_PATHS sets
npx ts-node scripts/build-sitemaps.ts     # Updates all XML sitemaps
```

### 3. Verification Commands (Claude Does This)
Test the changes work:

```bash
# Check HTTP status and X-Robots-Tag header
curl -I "https://whpcodes.com/whop/TARGET-SLUG"

# Check meta robots tag in HTML (only for 200 responses)
curl -s "https://whpcodes.com/whop/TARGET-SLUG" | grep -i '<meta name="robots"'

# Expected results:
# - INDEXABLE: 200 status + NO X-Robots-Tag + meta robots "index, follow"
# - NOINDEX: 200 status + X-Robots-Tag "noindex, follow" + meta robots "noindex, follow"  
# - GONE: 410 status
```

### 4. Verify Sitemap Placement
Check URLs appear in correct sitemaps:
- **Indexable**: https://whpcodes.com/sitemaps/index-1.xml
- **Noindex**: https://whpcodes.com/sitemaps/noindex.xml  
- **Gone**: https://whpcodes.com/sitemaps/gone.xml

### 5. Deploy (User Does This)
User must deploy to production for changes to take effect on live site.

## üîß Technical Details

### Files That Get Modified:
- `src/app/_generated/seo-indexes.ts` (auto-generated by build-seo-indexes.ts)
- `public/sitemaps/index-1.xml` (auto-generated by build-sitemaps.ts)
- `public/sitemaps/noindex.xml` (auto-generated by build-sitemaps.ts)
- `public/sitemaps/gone.xml` (auto-generated by build-sitemaps.ts)

### How It Works:
1. **Middleware** (`src/middleware.ts`) reads `NOINDEX_PATHS` set to add X-Robots-Tag headers
2. **Page component** (`src/app/whop/[slug]/page.tsx`) reads `indexingStatus` to set meta robots tags
3. **Sitemap scripts** read database to categorize URLs into correct XML files

### Expected Count Changes:
Always verify sitemap counts make sense:
- INDEX ‚Üí NOINDEX: index-1.xml (-1), noindex.xml (+1)
- NOINDEX ‚Üí INDEX: noindex.xml (-1), index-1.xml (+1)
- Any ‚Üí GONE: original sitemap (-1), gone.xml (+1)

## ‚ö†Ô∏è Critical Reminders

1. **Database changes must be done FIRST** (user responsibility)
2. **Build process reads current database state** to generate files
3. **Deployment required** for changes to take effect
4. **Never manually edit generated files** - they get overwritten
5. **Test locally after build, then deploy for live changes**

## üéØ Example Workflow

**User Request**: "Move 'the-flip-finders-community' from noindex to indexable"

**Claude Actions**:
1. Ask user to run: `UPDATE "Whop" SET "indexingStatus" = 'INDEX', "retirement" = 'NONE' WHERE slug = 'the-flip-finders-community';`
2. Run: `npm run build` 
3. Verify: `curl -I "https://whpcodes.com/whop/the-flip-finders-community"` (expect 200, no X-Robots-Tag)
4. Check sitemap: Verify appears in index-1.xml, not in noindex.xml
5. Confirm user needs to deploy for live changes

## üìä Success Criteria
- Correct HTTP status and headers
- Proper meta robots tags  
- URL appears in correct sitemap
- Counts make sense (old sitemap -1, new sitemap +1)
- No conflicting signals

**This process ensures clean, reliable indexing status changes! üéâ**